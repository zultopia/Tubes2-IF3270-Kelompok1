# ğŸ§  Deep Learning from Scratch: CNN & RNN Implementation

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Keras](https://img.shields.io/badge/Keras-2.x-red.svg)](https://keras.io)
[![NumPy](https://img.shields.io/badge/NumPy-1.x-orange.svg)](https://numpy.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Tugas Besar #2 IF3270 Pembelajaran Mesin**  
> *Implementasi Convolutional Neural Network dan Recurrent Neural Network dari Awal*

## ğŸ“ Deskripsi

Proyek ini mengimplementasikan tiga arsitektur deep learning utama **dari awal (from scratch)** menggunakan hanya NumPy sebagai library matematika dasar:

- ğŸ–¼ï¸ **Convolutional Neural Network (CNN)** untuk klasifikasi gambar CIFAR-10
- ğŸ”„ **Simple Recurrent Neural Network (RNN)** untuk klasifikasi sentimen teks
- ğŸ§® **Long Short-Term Memory (LSTM)** untuk klasifikasi sentimen teks

Implementasi mencakup forward propagation, backward propagation, dan training loop yang complete, kemudian dibandingkan dengan implementasi Keras untuk validasi akurasi.

## ğŸ‘¥ Disusun Oleh Kelompok 1

| Nama | NIM | Kontribusi |
|------|-----|------------|
| **Marzuli Suhada M** | 13522070 | LSTM Implementation & Backward Propagation |
| **Ahmad Mudabbir Arif** | 13522072 | CNN Implementation & Backward Propagation |
| **Naufal Adnan** | 13522116 | Simple RNN Implementation & Backward Propagation |

## ğŸ“ Struktur Proyek

```
TUBES2-ML/
â”œâ”€â”€ ğŸ“„ doc/
â”‚   â””â”€â”€ Laporan Tubes 2 Kelompok 1.pdf
â”œâ”€â”€ ğŸ’» src/
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ CNN/
â”‚   â”‚   â”œâ”€â”€ BaseLayer.py
â”‚   â”‚   â”œâ”€â”€ CNNFromScratch.py
â”‚   â”‚   â”œâ”€â”€ CNNUtils.py
â”‚   â”‚   â”œâ”€â”€ Conv2DLayer.py
â”‚   â”‚   â”œâ”€â”€ DenseLayer.py
â”‚   â”‚   â”œâ”€â”€ FlattenLayer.py
â”‚   â”‚   â””â”€â”€ PoolingLayers.py
â”‚   â”œâ”€â”€ ğŸ“Š dataset/
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â””â”€â”€ valid.csv
â”‚   â”œâ”€â”€ ğŸ§® LSTM/
â”‚   â”‚   â”œâ”€â”€ BaseLayer.py
â”‚   â”‚   â”œâ”€â”€ BidirectionalLSTM.py
â”‚   â”‚   â”œâ”€â”€ DenseLayer.py
â”‚   â”‚   â”œâ”€â”€ DropoutLayer.py
â”‚   â”‚   â”œâ”€â”€ EmbeddingLayer.py
â”‚   â”‚   â”œâ”€â”€ LSTMFromScratch.py
â”‚   â”‚   â””â”€â”€ LSTMLayer.py
â”‚   â”œâ”€â”€ ğŸ”„ RNN/
â”‚   â”‚   â”œâ”€â”€ BaseLayer.py
â”‚   â”‚   â”œâ”€â”€ BidirectionalRNNLayer.py
â”‚   â”‚   â”œâ”€â”€ DenseLayer.py
â”‚   â”‚   â”œâ”€â”€ DropoutLayer.py
â”‚   â”‚   â”œâ”€â”€ EmbeddingLayer.py
â”‚   â”‚   â”œâ”€â”€ RNNFromScratch.py
â”‚   â”‚   â””â”€â”€ SimpleRNNLayer.py
|   â”œâ”€â”€ ğŸ§ª test/
|   â”‚   â”œâ”€â”€ ğŸ“ˆ output_model/
|   â”‚   â”‚   â”œâ”€â”€ best_cnn_model.h5
|   â”‚   â”‚   â”œâ”€â”€ lstm_model.h5
|   â”‚   â”‚   â””â”€â”€ rnn_model.h5
â”‚   â”‚   â”œâ”€â”€ CNN.ipynb
â”‚   â”‚   â”œâ”€â”€ LSTM.ipynb
â”‚   â”‚   â””â”€â”€ simpleRNN.ipynb
â”‚   â””â”€â”€ ğŸ› ï¸ utils/
â”‚       â”œâ”€â”€ Activation.py
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

```bash
pip install numpy pandas matplotlib seaborn sklearn keras tensorflow
```

### Installation

```bash
https://github.com/zultopia/Tubes2-IF3270-Kelompok1
cd Tubes2-IF3270-Kelompok1
```

### Running the Models

#### 1. CNN untuk Klasifikasi Gambar CIFAR-10
```bash
cd test
jupyter notebook CNN.ipynb
```

#### 2. Simple RNN untuk Klasifikasi Sentimen
```bash
cd test
jupyter notebook simpleRNN.ipynb
```

#### 3. LSTM untuk Klasifikasi Sentimen
```bash
cd test
jupyter notebook LSTM.ipynb
```

## âœ¨ Fitur Utama

### ğŸ”§ Implementasi From Scratch
- âœ… **Forward Propagation** lengkap untuk semua layer
- âœ… **Backward Propagation** dengan Backpropagation Through Time (BPTT)
- âœ… **Batch Processing** untuk training dan inference yang efisien
- âœ… **Modular Architecture** dengan base classes dan inheritance

### ğŸ§ª Eksperimen Komprehensif

#### CNN Analysis
- ğŸ“Š Pengaruh jumlah layer konvolusi (1, 2, 3 layers)
- ğŸ” Pengaruh jumlah filter per layer (16-32, 32-64, 64-128)
- ğŸ“ Pengaruh ukuran kernel (3x3, 5x5, 7x7+3x3)
- ğŸŠ Perbandingan Max Pooling vs Average Pooling

#### RNN & LSTM Analysis
- ğŸ“ˆ Pengaruh jumlah layer (1, 2, 3 layers)
- ğŸ§  Pengaruh jumlah hidden units (32, 64, 128 cells)
- â†”ï¸ Perbandingan Unidirectional vs Bidirectional processing

### ğŸ“Š Validasi dan Benchmarking
- ğŸ¯ **100% Prediction Agreement** dengan Keras pada forward propagation
- ğŸ“ˆ Perbandingan performa menggunakan Macro F1-Score
- ğŸ“‰ Analisis training/validation loss curves
- ğŸ” Comprehensive error analysis

## ğŸ“ˆ Hasil Performa

### CNN (CIFAR-10)
| Konfigurasi | Test Accuracy | Macro F1-Score | Parameters |
|-------------|---------------|----------------|------------|
| 3 Conv Layers | **71.77%** | **0.7143** | 356,810 |
| Large Filters | 70.98% | 0.7065 | 1,125,642 |
| 3x3 Kernels | 69.68% | 0.6965 | 545,098 |

### RNN & LSTM (NusaX-Sentiment)
| Model | Architecture | Macro F1-Score | Parameters |
|-------|--------------|----------------|------------|
| **LSTM (1 Layer)** | Bidirectional | **0.7505** | 890,755 |
| RNN (2 Layers) | Bidirectional | 0.5571 | 816,899 |
| RNN (Bidirectional) | Single Layer | 0.5701 | 825,347 |

## ğŸ“Š Dataset

- **CIFAR-10**: 50,000 training + 10,000 test images (32x32 RGB)
  - Split: 40k train, 10k validation, 10k test
- **NusaX-Sentiment**: Indonesian sentiment classification dataset
  - 3 classes: positive, negative, neutral

## ğŸ› ï¸ Teknologi

- **Core**: Python 3.8+, NumPy
- **Validation**: Keras/TensorFlow
- **Visualization**: Matplotlib, Seaborn
- **Metrics**: Scikit-learn
- **Development**: Jupyter Notebook

## ğŸ“š Key Learnings

### ğŸ† Achievements
- âœ… **Perfect Forward Propagation**: 100% agreement dengan Keras
- âœ… **Complete BPTT Implementation**: Full backward propagation untuk RNN/LSTM
- âœ… **Batch Processing**: Efficient training dengan berbagai batch sizes
- âœ… **Hyperparameter Analysis**: Comprehensive experiments dengan 15+ konfigurasi

### ğŸ“ Insights
- ğŸ§  **CNN**: Kernel 3x3 optimal untuk images kecil, Max Pooling > Average Pooling
- ğŸ”„ **RNN**: Bidirectional processing memberikan +51% improvement
- ğŸ§® **LSTM**: Single layer lebih baik dari multi-layer pada dataset kecil
- âš–ï¸ **Trade-off**: Model complexity vs generalization capability

## ğŸ“– Documentation

Dokumentasi lengkap tersedia di [Laporan Tugas Besar](doc/Laporan%20Tubes%202%20Kelompok%201.pdf) yang mencakup:
- ğŸ”¬ Analisis mendalam setiap arsitektur
- ğŸ“Š Visualisasi hasil eksperimen
- ğŸ§® Formulasi matematis implementasi
- ğŸ“ˆ Perbandingan performa detail

## ğŸ”§ Usage Examples

### Menggunakan CNN From Scratch
```python
from src.CNN import CNNFromScratch

# Load model
cnn_model = CNNFromScratch()
cnn_model.load_from_keras('test/output_model/best_cnn_model.h5')

# Prediksi
predictions = cnn_model.predict(x_test, batch_size=32)
f1_score = cnn_model.evaluate(x_test, y_test)
```

### Menggunakan LSTM From Scratch
```python
from src.LSTM import LSTMFromScratch

# Inisialisasi model
lstm_model = LSTMFromScratch(learning_rate=0.001)
lstm_model.add_embedding_layer(vocab_size, embedding_dim)
lstm_model.add_bidirectional_lstm_layer(units=64)
lstm_model.add_dense_layer(units=num_classes, activation='softmax')

# Training
history = lstm_model.fit(X_train, y_train, epochs=10, batch_size=32)
```

## ğŸ§ª Reproducing Results

Untuk mereproduksi hasil eksperimen:

1. **CNN Experiments**:
   ```bash
   cd test
   jupyter notebook CNN.ipynb
   # Jalankan semua cell untuk eksperimen lengkap
   ```

2. **RNN Experiments**:
   ```bash
   cd test
   jupyter notebook simpleRNN.ipynb
   # Eksperimen hyperparameter RNN
   ```

3. **LSTM Experiments**:
   ```bash
   cd test
   jupyter notebook LSTM.ipynb
   # Analisis performa LSTM
   ```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ› Issues & Troubleshooting

### Common Issues
- **Memory Error**: Reduce batch size dalam training
- **Slow Training**: Gunakan batch processing yang lebih kecil
- **Gradient Explosion**: Implement gradient clipping

### Contact
Jika menemukan bug atau memiliki pertanyaan, silakan buat issue atau hubungi tim pengembang.

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ™ Acknowledgments

- **Institut Teknologi Bandung** - IF3270 Pembelajaran Mesin
- **Dive into Deep Learning** - Mathematical foundations
- **Keras Documentation** - Implementation reference
- **NumPy Community** - Core computational library
- **NusaX Team** - Indonesian sentiment dataset

## ğŸ“š References

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
- Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation.
- LeCun, Y., et al. (1998). Gradient-based learning applied to document recognition.
- Zhang, A., et al. (2021). Dive into Deep Learning. Available at: https://d2l.ai/

---

<div align="center">

**ğŸ“ Tugas Besar IF3270 Pembelajaran Mesin 2024/2025**

Made with â¤ï¸ by Kelompok 1

[![GitHub](https://img.shields.io/badge/GitHub-Repository-black.svg)](https://github.com/zultopia/Tubes2-IF3270-Kelompok1)
[![Report](https://img.shields.io/badge/ğŸ“„-Laporan-blue.svg)](doc/Laporan%20Tubes%202%20Kelompok%201.pdf)

</div>